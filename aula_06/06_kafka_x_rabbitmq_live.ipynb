{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RabbitMQ: summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![exchanges-topic-fanout-direct](https://s3-sa-east-1.amazonaws.com/lcpi/2c193eaf-55a2-4a06-896e-d9e60e57b4fd.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Producer / Produtor: É a entidade que envia as mensagens para o RabbitMQ. Ele publica as mensagens em uma fila ou tópico específico.\n",
    "\n",
    "* Queue / Fila: É um buffer que armazena as mensagens enviadas pelos produtores. As mensagens são mantidas na fila até que sejam consumidas pelos consumidores.\n",
    "\n",
    "* Consumer / Consumidor: É a entidade que recebe as mensagens do RabbitMQ. Ele se inscreve em uma fila ou tópico específico e consome as mensagens disponíveis.\n",
    "\n",
    "* Exchange: É um componente que recebe as mensagens dos produtores e as encaminha para as filas ou tópicos correspondentes. O Exchange define as regras de roteamento das mensagens.\n",
    "\n",
    "* Route / Rota: É a configuração que define o caminho das mensagens do Exchange para as filas ou tópicos correspondentes. As rotas são criadas com base em critérios como o nome da fila ou tópico, a chave de roteamento e o tipo de exchange.\n",
    "\n",
    "* Bindings / Ligações: É a associação entre uma fila ou tópico e uma rota. Os bindings definem quais mensagens serão encaminhadas para qual fila ou tópico.\n",
    "\n",
    "* Broker:  É responsável por garantir a confiabilidade e a integridade do sistema de mensageria, controlando o fluxo de mensagens e garantindo que as mensagens sejam entregues na ordem correta e sem perda de dados. Ele também é capaz de lidar com situações de alta demanda de tráfego de mensagens, escalando horizontalmente a capacidade do sistema e distribuindo a carga de trabalho entre vários nós. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   | RabbitMQ |\n",
    "|---|---       |\n",
    "|Message retention / lifetime| Excluded after acknowledgement | \n",
    "|Consumer Mode | Smart broker/dumb consumer |  \n",
    "|Topology| Exchange type: Direct, Fan out, Topic, Header-based |\n",
    "|Message ordering| Not supported|\n",
    "|Delivery order guarantees| Doesn't guarantee atomicity, even in single queue|\n",
    "|Message priorities| Set though priority queues |\n",
    "\n",
    "* Atomicity / atomicidade: Controle sobre inicio e fim da transação, é a garantia que todo o bloco de transações foi executado integralmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka: overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Apache Kafka é uma **plataforma distribuída** de transmissão de dados que é capaz de publicar, subscrever, armazenar e processar fluxos de registro em tempo real. Essa plataforma foi desenvolvida para processar fluxos de dados provenientes de diversas fontes e entregá-los a vários clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kafka-architecture](https://s3-sa-east-1.amazonaws.com/lcpi/032ec305-71c0-4b07-8f87-f56849c021c4.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seus principais componentes são:\n",
    "\n",
    "1. Broker: um servidor que recebe e armazena as mensagens produzidas pelos produtores e as distribui para os consumidores. Cada broker é responsável por um conjunto de partições dos tópicos.\n",
    "\n",
    "2. Tópico: uma categoria de mensagens que são produzidas e consumidas no Kafka. Cada mensagem pertence a um tópico, que pode ter várias partições distribuídas entre os brokers.\n",
    "\n",
    "3. Partição: uma porção ordenada e imutável de um tópico. Cada partição é replicada em vários brokers para garantir a disponibilidade e a tolerância a falhas.\n",
    "\n",
    "4. Produtor: um cliente que envia mensagens para um ou mais tópicos do Kafka. O produtor pode escolher em que partição enviar cada mensagem ou deixar o Kafka escolher automaticamente.\n",
    "\n",
    "5. Consumidor: um cliente que recebe mensagens de um ou mais tópicos do Kafka. Cada consumidor pertence a um grupo de consumidores e lê uma ou mais partições de cada tópico.\n",
    "\n",
    "6. Grupo de consumidores: um conjunto de consumidores que compartilham a leitura das partições de um tópico. Cada partição só pode ser lida por um consumidor de cada grupo, o que permite escalar o processamento dos dados.\n",
    "\n",
    "7. ZooKeeper: um serviço de coordenação distribuído que é utilizado pelo Kafka para gerenciar os brokers, os tópicos e os grupos de consumidores. O ZooKeeper armazena informações como as configurações dos brokers, os offsets de leitura dos consumidores e os líderes das partições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   | Kafka |\n",
    "|---|---       |\n",
    "|Message retention/lifetime| Policy-based (e.g., 30 days) | \n",
    "|Consumer Mode | Dumb broker/smart consumer |  \n",
    "|Topology| Publish/subscribe based |\n",
    "|Message ordering| Guaranteed within each partition|\n",
    "|Delivery order guarantees| Entire batch within a partition guaranteed to either pass or fails|\n",
    "|Message priorities| Not supported |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka vs. RabbitMQ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   | Kafka | RabbitMQ |\n",
    "|---|---       |---|\n",
    "|Message retention/lifetime| Policy-based (e.g., 30 days) | Excluded after acknowledgement | \n",
    "|Consumer Mode | Dumb broker/smart consumer |  Smart broker/dumb consumer |\n",
    "|Topology| Publish/subscribe based | Exchange type: Direct, Fan out, Topic, Header-based |\n",
    "|Message ordering| Guaranteed within each partition| Not supported|\n",
    "|Delivery order guarantees| Entire batch within a partition guaranteed to either pass or fails| Doesn't guarantee atomicity, even in single queue| \n",
    "|Message priorities| Not supported |Set though priority queues |\n",
    "\n",
    "* Referências: [upsolver](https://www.upsolver.com/blog/kafka-versus-rabbitmq-architecture-performance-use-case) e [Simplilearn](https://www.simplilearn.com/kafka-vs-rabbitmq-article#:~:text=RabbitMQ%20is%20best%20for%20transactional,logging%20statistics%2C%20and%20system%20activity.) acessados em 01/05/2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka: instalação\n",
    "\n",
    "Não pule nenhuma instrução!\n",
    "\n",
    "Referência: [kontext](https://kontext.tech/article/1047/install-and-run-kafka-320-on-wsl) acessado em 01/05/2023."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instale o Open JDK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "    sudo apt update\n",
    "    sudo apt install default-jre\n",
    "    sudo apt install openjdk-11-jre-headless\n",
    "    sudo apt install openjdk-8-jre-headless\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique a versão do Java com\n",
    "\n",
    "```bash\n",
    "    java -version\n",
    "```\n",
    "\n",
    "e o resultado esperado deve ser similar a \n",
    "\n",
    "```bash\n",
    "    openjdk 11.0.18 2023-01-17\n",
    "    OpenJDK Runtime Environment (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1)\n",
    "    OpenJDK 64-Bit Server VM (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1, mixed mode)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure a variável JAVA_HOME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abra o arquivo\n",
    "\n",
    "```bash\n",
    "    nano ~/.bash\n",
    "```\n",
    "\n",
    "e adicione a linha abaixo, sem mudar o texto!\n",
    "\n",
    "```bash\n",
    "    export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64\n",
    "```\n",
    "\n",
    "Confirme o procedimento digitando \n",
    "\n",
    "```bash\n",
    "    echo $JAVA_HOME\n",
    "```\n",
    "\n",
    "e veja se o resultado corresponde à linha adicionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instale o  Kafka"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Baixe o binário no [site oficial](https://kafka.apache.org/downloads).\n",
    "   1. A aula e os exemplos usam a versão `kafka_2.13-3.4.0`.\n",
    "2. Mova o arquivo para a pasta `home` do `wsl`.\n",
    "3. Descompacte o arquivo.\n",
    "   ```bash\n",
    "        tar -xvzf  kafka_2.13-3.4.0.tgz\n",
    "   ```\n",
    "4. Verifique o local dos arquivos que serão utilizados.\n",
    "   ```bash\n",
    "        ls ls ~/kafka_2.13-3.4.0/bin/\n",
    "   ```\n",
    "\n",
    "   ![kafka_files](https://s3-sa-east-1.amazonaws.com/lcpi/b5e04924-3532-48f7-b248-dd9245974174.png)\n",
    "5. Crie a variável `$KAFKA_HOME`.\n",
    "   1. Edite o arquivo `~/.bashrc`.\n",
    "      ```bash\n",
    "         nano ~/.bashrc\n",
    "      ```\n",
    "   2. Adicione a linha\n",
    "      ```bash\n",
    "         export KAFKA_HOME=~/kafka_2.13-3.4.0/\n",
    "      ``` \n",
    "   3. Salve o arquivo e execute\n",
    "      ```bash\n",
    "         source ~/.bashrc\n",
    "      ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka: Inicializar o ambiente / servidor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Zookeper\n",
    "```bash\n",
    "     $KAFKA_HOME/bin/zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties\n",
    "```\n",
    "\n",
    "### Start Kafka server\n",
    "```bash\n",
    "    $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties\n",
    "```\n",
    "\n",
    "#### In case of error:\n",
    "1. Open `server.properties` in $KAFKA_HOME/config\n",
    "2. Find `logs.dir`, f. ex.: /tmp/kafka-logs\n",
    "3. Delete the file `meta.properties` in the path found above.\n",
    " \n",
    "\n",
    "### Create a topic \n",
    "```bash\n",
    "    $KAFKA_HOME/bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic my_topic\n",
    "```  \n",
    "\n",
    "### List topics\n",
    "```bash\n",
    "    $KAFKA_HOME/bin/kafka-topics.sh --list --bootstrap-server localhost:9092\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka: Encerre o ambiente / servidor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "    $KAFKA_HOME/bin/kafka-server-stop.sh $KAFKA_HOME/config/server.properties\n",
    "\n",
    "    $KAFKA_HOME/bin/zookeeper-server-stop.sh $KAFKA_HOME/config/zookeeper.properties\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando e consumindo mensagens: terminal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício\n",
    "---\n",
    "\n",
    "1. Inicie o ambiente / servidor.\n",
    "2. Inicie produtor e consumidor em terminais diferentes.\n",
    "3. Mande e receba mensagens.\n",
    "4. Encerre o ambiente e os serviços.\n",
    "\n",
    "---\n",
    "`producer`\n",
    "\n",
    "```bash\n",
    "    $KAFKA_HOME/bin/kafka-console-producer.sh --topic my_topic --bootstrap-server localhost:9092\n",
    "```\n",
    "---\n",
    "\n",
    "`consumer`\n",
    "\n",
    "```bash\n",
    "    $KAFKA_HOME/bin/kafka-console-consumer.sh --topic my_topic --from-beginning --bootstrap-server localhost:9092\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando e consumindo mensagens: python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício\n",
    "---\n",
    "\n",
    "1. Instale a biblioteca `kafka-python`.\n",
    "   ```bash\n",
    "        pip install kafka-python\n",
    "   ```\n",
    "2. Inicie o ambiente / servidor.\n",
    "3. Crie os scrips de produtor e consumidor.\n",
    "4. Inicialize o consumidor.\n",
    "5. Mande e receba mensagens.\n",
    "6. Encerre o ambiente e os serviços."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "`producer`\n",
    "\n",
    "```python\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'])\n",
    "topic = 'my_topic'\n",
    "# topic = 'kontext-events'\n",
    "\n",
    "for i in range(11):\n",
    "    msg = \"Mensagem {}\".format(i)\n",
    "    producer.send(topic, msg.encode('utf-8'))\n",
    "\n",
    "producer.flush()\n",
    "```\n",
    "---\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "`consumer`\n",
    "\n",
    "```python\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer('my_topic', bootstrap_servers=['localhost:9092'])\n",
    "\n",
    "for message in consumer:\n",
    "    print(message.value.decode('utf-8'))\n",
    "```\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
